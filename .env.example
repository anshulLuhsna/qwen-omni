# Qwen2.5-Omni-7B AWQ Environment Variables
# Copy this file to .env and update with your values

# Hugging Face token (optional, for gated models)
# Get your token from: https://huggingface.co/settings/tokens
HF_TOKEN=

# Enable fast file transfer (recommended)
HF_HUB_ENABLE_HF_TRANSFER=1

# CUDA settings
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# Model settings (optional overrides)
# MODEL_ID=Qwen/Qwen2.5-Omni-7B-AWQ
# MAX_NEW_TOKENS=1024
# TEMPERATURE=0.7
# TOP_P=0.9

# Server settings
# PORT=8000
# HOST=0.0.0.0
# WORKERS=1

# Audio settings
# SAMPLE_RATE=24000
# MAX_AUDIO_LENGTH=30

# Memory management
# TORCH_CUDA_MEMORY_FRACTION=0.95

# Logging
# LOG_LEVEL=INFO

# RunPod specific (set these in RunPod environment)
# RUNPOD_POD_ID=your_pod_id_here
# RUNPOD_API_KEY=your_api_key_here